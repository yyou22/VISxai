[meta title:"Intro to Adversarial Attacks" description:"A Beginner's Introduction to Adversarial Attacks" /]

// Scroller Tutorial
[var name:"barStep" value:0 /]
[Scroller currentStep:barStep]

  [Graphic]
  [/Graphic]

  [Step]

    [CustomHeader
        title:"Panda or Gibbon? How CNNs Get Fooled by Input Noises"
        subtitle:"A Beginner's Introduction to Adversarial Attacks"
        date:"July 31, 2024"
        authors:`[
        { name: "Yuzhe You", link: "FIXME" },
        { name: "Jian Zhao", link: "FIXME" }
        ]` /]

    [div className:"line"][/div]

    [div className:"text"]
        ## INTRODUCTION
        Though deep learning models have achieved remarkable success in diverse domains (e.g., faicial recognition, autonomous driving),
        these models have been proven to be quite brittle to perturbations around the input data.
        *Adversarial machine learning* (AML) studies attacks that can fool machine learning models into generating incorrect outcomes as well as the defenses against worst-case attacks to strength model robustness. 
    [/div]
  [/Step]

  [Step]
    The **bar** on the right belongs to this first Scroller component. 
    
    Let's first look at how we can animate **within** a Scroller. Watch how it rotates 
    as you move to the next step.
  [/Step]

[/Scroller]